{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Unpack both parts of the Yahoo dataset\n",
    "2. Join them together (execute in command line / terminal): cat FUllOct2007.xml.part1 FullOct2007.xml.part2 > full.xml\n",
    "3. Install xml_split: sudo apt-get install xml-twig-tools\n",
    "4. Split the full file into approx. 1Gb big files: xml_split -s 1Gb full.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from html import unescape\n",
    "from tqdm import tqdm\n",
    "from dateutil.parser import parse\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def clean(s):\n",
    "    regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    s = re.sub(regex, \"[REF]\", s)\n",
    "    s = unescape(BeautifulSoup(s,'lxml').get_text())\n",
    "    if \"<br />\" in s:\n",
    "        s=re.sub(r'(\\n|<br />)', \" \", s)\n",
    "    else:\n",
    "        s=re.sub(r'\\n', \"  \", s)\n",
    "    s = re.sub(r\"\\'\", \"'\", s, flags=re.MULTILINE)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('touche22-task2-stance-dataset', sep='\\t')\n",
    "i = df[df['ds']=='yahoo'].id.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "idx=\"\"\n",
    "question=[]\n",
    "ids=[]\n",
    "answers = []\n",
    "ans_niklas=[]\n",
    "ans_found=[]\n",
    "uris=[]\n",
    "found=\"\"\n",
    "for file in tqdm(os.listdir(\"full\")): #path to the directory with the split dataset (e.g., the folder is called full)\n",
    "    print(file)\n",
    "    if '-' in file:\n",
    "        tree = ET.parse(\"full/\"+file)\n",
    "        for r in tree.iter(tag='vespaadd'):\n",
    "            r = r[0]\n",
    "            uri=r.findtext('uri')\n",
    "            if int(uri) in i:\n",
    "                for idx, row in df.iterrows():\n",
    "                    if int(uri)==row.id:\n",
    "                        df.at[idx,'question'] = clean(r.findtext('subject'))\n",
    "                        df.at[idx,'answer'] = clean(r.findtext('bestanswer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # result df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
