{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "868655\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('touche-task2-passages-version-002.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "    \n",
    "collection_list = {}\n",
    "maps = {}\n",
    "\n",
    "print (len(json_list))\n",
    "for ind, json_str in enumerate(json_list):\n",
    "    result = json.loads(json_str)\n",
    "    collection_list.update({result['id']: result['contents']})\n",
    "    maps.update({ind: result['id']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/notebook/Touche22/test/id_doc_map22.pickle', 'rb') as handle:\n",
    "    mapping_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '54353', '1']\n",
      "['0', '54345', '2']\n",
      "['0', '7883', '3']\n",
      "['0', '9524', '4']\n",
      "['0', '12171', '5']\n",
      "['0', '8329', '6']\n",
      "['0', '7890', '7']\n",
      "['0', '9691', '8']\n",
      "['0', '12162', '9']\n",
      "['0', '12121', '10']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "tsv_file = open(\"/notebook/Touche22/test/ranking_7.tsv\")\n",
    "read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "\n",
    "common_list = []\n",
    "i = 0\n",
    "for row in read_tsv:\n",
    "    if (i < 10):\n",
    "        print(row)\n",
    "        i = i +1\n",
    "    doq_n = str(int(row[0]))\n",
    "    pass_idx = mapping_dict[int(row[1])]\n",
    "    rank = row[2]\n",
    "    \n",
    "    res_str = doq_n + ' Q0 ' + str(pass_idx) + \" \" + str(rank) + \" \" + str(1./int(rank))+ \" colbert\"\n",
    "    \n",
    "    common_list.append(res_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/notebook/Touche22/test/titles.pickle', 'rb') as handle:\n",
    "    titles = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Which is better, a laptop or a desktop?',\n",
       " 'Which is better, Canon or Nikon?',\n",
       " 'What are the advantages and disadvantages of PHP over Python and vice versa?',\n",
       " 'Why is Linux better than Windows?',\n",
       " 'Train or plane? Which is the better choice?',\n",
       " 'Should one prefer Chinese medicine or Western medicine?',\n",
       " 'Do you prefer cats or dogs, and why?',\n",
       " 'What is the better way to grill outdoors: gas or charcoal?',\n",
       " 'Which is better, MAC or PC?',\n",
       " 'Which is better, Pepsi or Coke?',\n",
       " 'What is better, Google search or Yahoo search?',\n",
       " 'Which browser is better, Internet Explorer or Firefox?',\n",
       " 'Which is a better vehicle: BMW or Audi?',\n",
       " 'Which one is better, an electric stove or a gas stove?',\n",
       " 'What planes are best, Boeing or Airbus?',\n",
       " 'Should I buy an Xbox or a PlayStation?',\n",
       " 'What is better: ASP or PHP?',\n",
       " 'What is better for the environment, a real or a fake Christmas tree?',\n",
       " 'What IDE is better for Java: NetBeans or Eclipse?',\n",
       " 'Is OpenGL better than Direct3D in terms of portability to different platforms?',\n",
       " 'Which four wheel truck is better: Ford or Toyota?',\n",
       " 'Should I prefer a Leica camera over Nikon for portrait photographs?',\n",
       " 'Is pasta healthier than pizza?',\n",
       " 'What is better at reducing fever in children, Ibuprofen or Aspirin?',\n",
       " 'Should I buy steel or ceramic knives?',\n",
       " 'Is morning or afternoon sun the best for fruit trees?',\n",
       " 'What is better for back pain, chiropractic therapy or physical therapy?',\n",
       " 'Is Kenya or Tanzania better for a safari?',\n",
       " 'Which is better, Family Guy or The Simpsons?',\n",
       " 'Which is more difficult, skiing or snowboarding?',\n",
       " 'Why is basketball better than football?',\n",
       " 'Who is stronger, Hulk or Superman?',\n",
       " 'Plastic pots or ceramic pots, which is better in terms of plant health?',\n",
       " 'Should I take the IELTS or the TOEFL?',\n",
       " 'Are online courses better than physical classrooms?',\n",
       " 'Who was a better boxer, Muhammad Ali or Joe Frazier?',\n",
       " \"Which technology performs better: Apple's or Google's?\",\n",
       " 'Who is better at learning a foreign language, kids or adults?',\n",
       " 'Which city is better, London or Paris?',\n",
       " 'Are artificial sweeteners better than white sugar?',\n",
       " 'Is it healthier to bake than to fry food?',\n",
       " 'Which algorithm is better, quicksort or merge sort?',\n",
       " 'What is better, cow milk or goat milk?',\n",
       " 'I am planning to buy sneakers: Which are better, Adidas or Nike?',\n",
       " 'Should I major in philosophy or psychology?',\n",
       " 'When are random forest classifiers better than decision trees?',\n",
       " 'What are the pros and cons of wood vs. stone mulch?',\n",
       " 'Is rain water better than tap water for plants?',\n",
       " 'Which is more environmentally friendly, a hybrid or a diesel?',\n",
       " 'Should I learn Python or R for data analysis?']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_common_list(common_list, numb):\n",
    "    ind_set = set()\n",
    "    for elem in common_list[:numb]:\n",
    "        elem = elem.split()\n",
    "        ind = int(elem[0])\n",
    "        #pass_idx = doc_ind2pass[elem[2]]\n",
    "        if ind not in ind_set:\n",
    "            print (titles[ind])\n",
    "            ind_set.add(ind)\n",
    "            print (\"\\n\")\n",
    "            try:\n",
    "                print (collection_list[elem[2]])\n",
    "            except:\n",
    "                print (\"bls\")\n",
    "            print (\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_common_list(common_list, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '54353', '1']\n",
      "['0', '54345', '2']\n",
      "['0', '7883', '3']\n",
      "['0', '9524', '4']\n",
      "['0', '12171', '5']\n",
      "['0', '8329', '6']\n",
      "['0', '7890', '7']\n",
      "['0', '9691', '8']\n",
      "['0', '12162', '9']\n",
      "['0', '12121', '10']\n"
     ]
    }
   ],
   "source": [
    "tsv_file = open(\"/notebook/Touche22/test/ranking_7.tsv\")\n",
    "read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "\n",
    "common_list = []\n",
    "i = 0\n",
    "for row in read_tsv:\n",
    "    if (i < 10):\n",
    "        print(row)\n",
    "        i = i +1\n",
    "    doq_n = str(int(row[0]) + 1)\n",
    "    pass_idx = mapping_dict[int(row[1])]\n",
    "    rank = row[2]\n",
    "    \n",
    "    res_str = doq_n + ' Q0 ' + str(pass_idx) + \" \" + str(rank) + \" \" + str(1./int(rank))+ \"Colbert fine-tune\"\n",
    "    \n",
    "    common_list.append(res_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 Q0 clueweb12-0207wb-45-15666___12 1 1.0Colbert fine-tune',\n",
       " '1 Q0 clueweb12-0207wb-45-15666___4 2 0.5Colbert fine-tune',\n",
       " '1 Q0 clueweb12-0001wb-72-30848___1 3 0.3333333333333333Colbert fine-tune',\n",
       " '1 Q0 clueweb12-0505wb-78-06026___3 4 0.25Colbert fine-tune',\n",
       " '1 Q0 clueweb12-1612wb-49-30112___1 5 0.2Colbert fine-tune',\n",
       " '1 Q0 clueweb12-0013wb-19-15392___6 6 0.16666666666666666Colbert fine-tune',\n",
       " '1 Q0 clueweb12-0001wb-72-30848___8 7 0.14285714285714285Colbert fine-tune']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_list[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = classification_results['max'][index]\n",
    "        if label == 'NEUTRAL':\n",
    "            continue\n",
    "\n",
    "        classification_confidence = classification_results[label][index]\n",
    "        sentence_text = row['sentence']\n",
    "\n",
    "        for s in sentences:\n",
    "            if s.text == sentence_text:\n",
    "                sentence = s\n",
    "                break\n",
    "        sentences.remove(sentence)\n",
    "        sentence.set_confidence(classification_confidence.item())\n",
    "\n",
    "        contained_aspects = find_aspects(sentence.text, aspects)\n",
    "        if (label == 'BETTER' and row['object_a'] == obj_a.name) or (\n",
    "                label == 'WORSE' and row['object_b'] == obj_a.name):\n",
    "            add_points(contained_aspects, obj_a, sentence,\n",
    "                       max_sentscore, score_function, threshold_sentences, threshold_score)\n",
    "        else:\n",
    "            add_points(contained_aspects, obj_b, sentence,\n",
    "                       max_sentscore, score_function, threshold_sentences, threshold_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_stance(obj1, obj2, sentence, classification_results):\n",
    "    #print (obj1, obj2, sentence)\n",
    "    if (obj1 not in sentence):\n",
    "        return 'SECOND'\n",
    "    if (obj2 not in sentence):\n",
    "        return 'FIRST'\n",
    "    if (obj1 not in sentence and obj2 not in sentence):\n",
    "        return 'NO'\n",
    "    if classification_results['max'] == ['BETTER']:\n",
    "        return 'FIRST'\n",
    "    if classification_results['max'] == ['WORSE']:\n",
    "        return 'SECOND'\n",
    "    else:\n",
    "        return 'NEUTRAL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/notebook/cam/src/Backend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from ml_approach.classify import (classify_sentences, evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_approach.sentence_preparation_ML import prepare_sentence_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_sentences = 'While it seems readers favour Nikon, it’s hard to tell which one is actually the best. Canon and Nikon are both multi-billion dollar optical companies that have been making some of the finest optics for consumers, military and industrial applications for decades. They compete so heavily against each other in the same market that if one really were the best, the other would have gone out of business long ago. These companies tend to merely leapfrog one another in terms of who comes out top at the end of each year. The facts Which camera the is most popular? Experts and users reviewed Canon and Nikon DSLRs worldwide. In looking at reviews and calculating an average score out of 10 points between 2006 and 2011, this is what they rated.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_sentences = prepare_sentence_DF(all_sentences, 'canon', 'nikon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.19.1 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/sklearn/base.py:306: UserWarning: Trying to unpickle estimator Pipeline from version 0.19.1 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'models.BLSTMEncoder' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/serialization.py:786: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.LSTM' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 44(/44) words with glove vectors\n",
      "Vocab size : 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebook/cam/src/Backend/cam_pretrained/infersent/models.py:197: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  sentences = np.array(sentences)[idx_sort]\n",
      "/notebook/cam/src/Backend/cam_pretrained/infersent/models.py:209: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  sentences[stidx:stidx + bsize]), volatile=True)\n"
     ]
    }
   ],
   "source": [
    "classification_results = classify_sentences(prepared_sentences, 'infersent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SECOND'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "define_stance('canon', 'nikon', all_sentences, classification_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## final submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('objects.pickle', 'rb') as handle:\n",
    "    objects = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "objs_text = {}\n",
    "for elem in objects:\n",
    "    objs_text.update({elem:[]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "tsv_file = open(\"/notebook/Touche22/test/ranking_7.tsv\")\n",
    "read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "\n",
    "common_list = []\n",
    "i = 0\n",
    "num_of_doc = 100\n",
    "\n",
    "for row in read_tsv:\n",
    "\n",
    "    doq_n = str(int(row[0]) + 1)\n",
    "    pass_idx = mapping_dict[int(row[1])]\n",
    "    rank = row[2]\n",
    "    \n",
    "    #define passage text\n",
    "    passage = collection_list[pass_idx]\n",
    "    \n",
    "    #define objects\n",
    "    o1_o2 = objects[int(row[0])]\n",
    "    \n",
    "    if (len(objs_text[o1_o2]) < 100):\n",
    "        objs_text[o1_o2].append(passage)\n",
    "    \n",
    "    # define stance\n",
    "    #prepared_sentences = prepare_sentence_DF(passage, o1, o2)\n",
    "    #classification_results = classify_sentences(prepared_sentences, 'infersent')\n",
    "    \n",
    "    \n",
    "    #res = define_stance(o1, o2, passage , classification_results)\n",
    "    \n",
    "        if (i < 10):\n",
    "            print(row)\n",
    "            i = i +1\n",
    "            print (\"objects\", o1_o2)\n",
    "            print (\"passage\", passage)\n",
    "            #print (\"stance\", res)\n",
    "        res_str = [doq_n, 'Q0', pass_idx, rank, str(1./int(rank)), \"Colbert \"]\n",
    "\n",
    "        common_list.append(res_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', 'Q0', 'clueweb12-0207wb-45-15666___12', '1', '1.0', 'Colbert '],\n",
       " ['1', 'Q0', 'clueweb12-0207wb-45-15666___4', '2', '0.5', 'Colbert '],\n",
       " ['1',\n",
       "  'Q0',\n",
       "  'clueweb12-0001wb-72-30848___1',\n",
       "  '3',\n",
       "  '0.3333333333333333',\n",
       "  'Colbert ']]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_list[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list(zip(*common_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Q0\n",
       "1       Q0\n",
       "2       Q0\n",
       "3       Q0\n",
       "4       Q0\n",
       "        ..\n",
       "4995    Q0\n",
       "4996    Q0\n",
       "4997    Q0\n",
       "4998    Q0\n",
       "4999    Q0\n",
       "Name: Q0, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df['Q0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_n</th>\n",
       "      <th>stance</th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clueweb12-0001wb-72-30848___26</td>\n",
       "      <td>99</td>\n",
       "      <td>0.010101010101010102</td>\n",
       "      <td>Colbert edinburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clueweb12-0301tw-22-15272___3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Colbert edinburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clueweb12-0006wb-73-24342___85</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Colbert edinburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clueweb12-1502wb-62-28658___7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3333333333333333</td>\n",
       "      <td>Colbert edinburg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    doc_n stance                              id rank                 score  \\\n",
       "98      1    NaN  clueweb12-0001wb-72-30848___26   99  0.010101010101010102   \n",
       "99      2    NaN   clueweb12-0301tw-22-15272___3    1                   1.0   \n",
       "100     2    NaN  clueweb12-0006wb-73-24342___85    2                   0.5   \n",
       "101     2    NaN   clueweb12-1502wb-62-28658___7    3    0.3333333333333333   \n",
       "\n",
       "               method  \n",
       "98   Colbert edinburg  \n",
       "99   Colbert edinburg  \n",
       "100  Colbert edinburg  \n",
       "101  Colbert edinburg  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df[98:102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_n</th>\n",
       "      <th>stance</th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clueweb12-0001wb-72-30848___26</td>\n",
       "      <td>99</td>\n",
       "      <td>0.010101010101010102</td>\n",
       "      <td>Colbert edinburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clueweb12-0301tw-22-15272___3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Colbert edinburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clueweb12-0006wb-73-24342___85</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Colbert edinburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clueweb12-1502wb-62-28658___7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3333333333333333</td>\n",
       "      <td>Colbert edinburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clueweb12-0111wb-59-06595___15</td>\n",
       "      <td>4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Colbert edinburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clueweb12-0006wb-08-02130___4</td>\n",
       "      <td>98</td>\n",
       "      <td>0.01020408163265306</td>\n",
       "      <td>Colbert edinburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clueweb12-1218wb-42-10825___5</td>\n",
       "      <td>99</td>\n",
       "      <td>0.010101010101010102</td>\n",
       "      <td>Colbert edinburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clueweb12-0411wb-80-10320___5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>Colbert edinburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clueweb12-1215wb-30-08226___4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Colbert edinburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clueweb12-0612wb-19-00414___12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Colbert edinburg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    doc_n stance                              id rank                 score  \\\n",
       "98      1    NaN  clueweb12-0001wb-72-30848___26   99  0.010101010101010102   \n",
       "99      2    NaN   clueweb12-0301tw-22-15272___3    1                   1.0   \n",
       "100     2    NaN  clueweb12-0006wb-73-24342___85    2                   0.5   \n",
       "101     2    NaN   clueweb12-1502wb-62-28658___7    3    0.3333333333333333   \n",
       "102     2    NaN  clueweb12-0111wb-59-06595___15    4                  0.25   \n",
       "..    ...    ...                             ...  ...                   ...   \n",
       "196     2    NaN   clueweb12-0006wb-08-02130___4   98   0.01020408163265306   \n",
       "197     2    NaN   clueweb12-1218wb-42-10825___5   99  0.010101010101010102   \n",
       "198     2    NaN   clueweb12-0411wb-80-10320___5  100                  0.01   \n",
       "199     3    NaN   clueweb12-1215wb-30-08226___4    1                   1.0   \n",
       "200     3    NaN  clueweb12-0612wb-19-00414___12    2                   0.5   \n",
       "\n",
       "               method  \n",
       "98   Colbert edinburg  \n",
       "99   Colbert edinburg  \n",
       "100  Colbert edinburg  \n",
       "101  Colbert edinburg  \n",
       "102  Colbert edinburg  \n",
       "..                ...  \n",
       "196  Colbert edinburg  \n",
       "197  Colbert edinburg  \n",
       "198  Colbert edinburg  \n",
       "199  Colbert edinburg  \n",
       "200  Colbert edinburg  \n",
       "\n",
       "[103 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df[98:201]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_n</th>\n",
       "      <th>stance</th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clueweb12-0505wb-78-06026___3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Colbert edinburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clueweb12-1612wb-13-07110___2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Colbert edinburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clueweb12-0301wb-84-10147___2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3333333333333333</td>\n",
       "      <td>Colbert edinburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>clueweb12-1716wb-73-00607___3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>Colbert edinburg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc_n stance                             id rank               score  \\\n",
       "0     1    NaN  clueweb12-0505wb-78-06026___3    1                 1.0   \n",
       "1     1    NaN  clueweb12-1612wb-13-07110___2    2                 0.5   \n",
       "2     1    NaN  clueweb12-0301wb-84-10147___2    3  0.3333333333333333   \n",
       "3     1    NaN  clueweb12-1716wb-73-00607___3    4                0.25   \n",
       "\n",
       "             method  \n",
       "0  Colbert edinburg  \n",
       "1  Colbert edinburg  \n",
       "2  Colbert edinburg  \n",
       "3  Colbert edinburg  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "my_df = pd.DataFrame(columns =['doc_n', 'stance', 'id', 'rank', 'score', 'method'])\n",
    "my_df['doc_n'] = results[0]\n",
    "#my_df['Q0'] = ['Q0' for elem in results[1]]\n",
    "my_df['id'] = results[2]\n",
    "my_df['rank'] = results[3]\n",
    "my_df['score'] = results[4]\n",
    "my_df['method'] = ['Colbert fine tune on touche data' for elem in results[5]]\n",
    "my_df['stance'] = stanses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.to_csv('colbert_fine_tune1.txt', header=None, index=None, sep=' ', line_terminator='\\n', mode='a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Colbert fine tune on touche data\n",
       "1       Colbert fine tune on touche data\n",
       "2       Colbert fine tune on touche data\n",
       "3       Colbert fine tune on touche data\n",
       "4       Colbert fine tune on touche data\n",
       "                      ...               \n",
       "4995    Colbert fine tune on touche data\n",
       "4996    Colbert fine tune on touche data\n",
       "4997    Colbert fine tune on touche data\n",
       "4998    Colbert fine tune on touche data\n",
       "4999    Colbert fine tune on touche data\n",
       "Name: method, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df['method']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "my_df.to_csv('colbert_ft.txt', header=None, index=None, sep='\\t', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_str = [doq_n, ' Q0 ', pass_idx, rank, str(1./int(rank)), \"Colbert fine-tune\"]\n",
    "    \n",
    "    common_list.append(res_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_common_list = []\n",
    "for elem in common_list:\n",
    "    ind = int(elem[0]) - 1\n",
    "    objs = objects[ind]\n",
    "    stance_ind = elem[1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stanses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objs_stances = {}\n",
    "stanses = []\n",
    "for elem in objects:\n",
    "    # define stance\n",
    "    print (elem)\n",
    "    passages = objs_text[elem]\n",
    "    #print (passages)\n",
    "    o1, o2 = elem.split(',')\n",
    "    prepared_sentences = prepare_sentence_DF(passages, o1, o2)\n",
    "    classification_results = classify_sentences(prepared_sentences, 'infersent')\n",
    "    #stanses = []\n",
    "    for ind, passage in enumerate(passages):\n",
    "        stanses.append(define_stance(o1, o2, passage , classification_results.iloc[ind]))\n",
    "    #objs_stances.update({elem:reses})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## final submission fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('number_map.pickle', 'rb') as handle:\n",
    "    ind_to_orig = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "pd_df = pd.DataFrame(columns =['doc_n', 'stance', 'id', 'rank', 'score', 'method'])\n",
    "pd_df= pd.read_csv('colbert_pretrained_by_me_fixed_topic.txt', names =['doc_n', 'stance', 'id', 'rank', 'score', 'method'], sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df['doc_n'] = [ind_to_orig[elem] for elem in pd_df['doc_n']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_n</th>\n",
       "      <th>stance</th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>SECOND</td>\n",
       "      <td>clueweb12-1612wb-13-07110___2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Colbert trained by me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>clueweb12-0505wb-78-06026___3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Colbert trained by me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>clueweb12-0301wb-84-10147___2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>Colbert trained by me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>clueweb12-1716wb-73-00607___3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>Colbert trained by me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>SECOND</td>\n",
       "      <td>clueweb12-1617wb-15-18627___1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>Colbert trained by me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>100</td>\n",
       "      <td>FIRST</td>\n",
       "      <td>clueweb12-1506wb-56-17825___25</td>\n",
       "      <td>96</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>Colbert trained by me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>100</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>clueweb12-1701wb-67-12398___1</td>\n",
       "      <td>97</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>Colbert trained by me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>100</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>clueweb12-0810wb-00-06776___27</td>\n",
       "      <td>98</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>Colbert trained by me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>100</td>\n",
       "      <td>FIRST</td>\n",
       "      <td>clueweb12-0209wb-35-13237___22</td>\n",
       "      <td>99</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>Colbert trained by me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>100</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>clueweb12-0010wb-07-08512___31</td>\n",
       "      <td>100</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>Colbert trained by me</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      doc_n   stance                              id  rank     score  \\\n",
       "0         2   SECOND   clueweb12-1612wb-13-07110___2     1  1.000000   \n",
       "1         2  NEUTRAL   clueweb12-0505wb-78-06026___3     2  0.500000   \n",
       "2         2  NEUTRAL   clueweb12-0301wb-84-10147___2     3  0.333333   \n",
       "3         2  NEUTRAL   clueweb12-1716wb-73-00607___3     4  0.250000   \n",
       "4         2   SECOND   clueweb12-1617wb-15-18627___1     5  0.200000   \n",
       "...     ...      ...                             ...   ...       ...   \n",
       "4995    100    FIRST  clueweb12-1506wb-56-17825___25    96  0.010417   \n",
       "4996    100  NEUTRAL   clueweb12-1701wb-67-12398___1    97  0.010309   \n",
       "4997    100  NEUTRAL  clueweb12-0810wb-00-06776___27    98  0.010204   \n",
       "4998    100    FIRST  clueweb12-0209wb-35-13237___22    99  0.010101   \n",
       "4999    100  NEUTRAL  clueweb12-0010wb-07-08512___31   100  0.010000   \n",
       "\n",
       "                     method  \n",
       "0     Colbert trained by me  \n",
       "1     Colbert trained by me  \n",
       "2     Colbert trained by me  \n",
       "3     Colbert trained by me  \n",
       "4     Colbert trained by me  \n",
       "...                     ...  \n",
       "4995  Colbert trained by me  \n",
       "4996  Colbert trained by me  \n",
       "4997  Colbert trained by me  \n",
       "4998  Colbert trained by me  \n",
       "4999  Colbert trained by me  \n",
       "\n",
       "[5000 rows x 6 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_n</th>\n",
       "      <th>stance</th>\n",
       "      <th>id</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>clueweb12-0207wb-45-15666___12</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Colbert fine tune on touche data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>SECOND</td>\n",
       "      <td>clueweb12-0207wb-45-15666___4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Colbert fine tune on touche data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>clueweb12-0001wb-72-30848___1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>Colbert fine tune on touche data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>clueweb12-0505wb-78-06026___3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>Colbert fine tune on touche data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>clueweb12-1612wb-49-30112___1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>Colbert fine tune on touche data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>100</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>clueweb12-1806wb-25-26496___8</td>\n",
       "      <td>96</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>Colbert fine tune on touche data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>100</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>clueweb12-1510wb-40-28311___11</td>\n",
       "      <td>97</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>Colbert fine tune on touche data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>100</td>\n",
       "      <td>SECOND</td>\n",
       "      <td>clueweb12-0010wb-07-08512___51</td>\n",
       "      <td>98</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>Colbert fine tune on touche data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>100</td>\n",
       "      <td>SECOND</td>\n",
       "      <td>clueweb12-1010wb-45-08505___170</td>\n",
       "      <td>99</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>Colbert fine tune on touche data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>100</td>\n",
       "      <td>FIRST</td>\n",
       "      <td>clueweb12-1712wb-07-08901___6</td>\n",
       "      <td>100</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>Colbert fine tune on touche data</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     doc_n   stance                               id  rank     score  \\\n",
       "0        2  NEUTRAL   clueweb12-0207wb-45-15666___12     1  1.000000   \n",
       "1        2   SECOND    clueweb12-0207wb-45-15666___4     2  0.500000   \n",
       "2        2  NEUTRAL    clueweb12-0001wb-72-30848___1     3  0.333333   \n",
       "3        2  NEUTRAL    clueweb12-0505wb-78-06026___3     4  0.250000   \n",
       "4        2  NEUTRAL    clueweb12-1612wb-49-30112___1     5  0.200000   \n",
       "...    ...      ...                              ...   ...       ...   \n",
       "4995   100  NEUTRAL    clueweb12-1806wb-25-26496___8    96  0.010417   \n",
       "4996   100  NEUTRAL   clueweb12-1510wb-40-28311___11    97  0.010309   \n",
       "4997   100   SECOND   clueweb12-0010wb-07-08512___51    98  0.010204   \n",
       "4998   100   SECOND  clueweb12-1010wb-45-08505___170    99  0.010101   \n",
       "4999   100    FIRST    clueweb12-1712wb-07-08901___6   100  0.010000   \n",
       "\n",
       "                                method  \n",
       "0     Colbert fine tune on touche data  \n",
       "1     Colbert fine tune on touche data  \n",
       "2     Colbert fine tune on touche data  \n",
       "3     Colbert fine tune on touche data  \n",
       "4     Colbert fine tune on touche data  \n",
       "...                                ...  \n",
       "4995  Colbert fine tune on touche data  \n",
       "4996  Colbert fine tune on touche data  \n",
       "4997  Colbert fine tune on touche data  \n",
       "4998  Colbert fine tune on touche data  \n",
       "4999  Colbert fine tune on touche data  \n",
       "\n",
       "[5000 rows x 6 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_df.to_csv('colbert_fine_tune1_fixed_topic.txt', header=None, index=None, sep=' ', line_terminator='\\n', mode='a')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('objects.pickle', 'rb') as handle:\n",
    "    objects = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/notebook/cam/src/Backend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = []\n",
    "for elem in common_list[:50]:\n",
    "    elem = elem.split()\n",
    "    ind = int(elem[0])\n",
    "    #pass_idx = doc_ind2pass[elem[2]]\n",
    "    \n",
    "    all_sentences.append(collection_list[elem[2]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['laptop, desktop', 'Canon, Nikon']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from ml_approach.classify import (classify_sentences, evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_approach.sentence_preparation_ML import prepare_sentence_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/bow_model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-92280be4b67a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprepared_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_sentence_DF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'laptop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'desktop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclassification_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepared_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/notebook/cam/src/Backend/ml_approach/classify.py\u001b[0m in \u001b[0;36mclassify_sentences\u001b[0;34m(sentences, model)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         model = load_model('data/bow_model.pkl',\n\u001b[0;32m---> 17\u001b[0;31m                            glove_path=None, infersent_path=None)\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebook/cam/src/Backend/cam_pretrained/model_util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(model, glove_path, infersent_path)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \"\"\"\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mglove_path\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minfersent_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'infersentfeature'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglove_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglove_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_read_fileobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/bow_model.pkl'"
     ]
    }
   ],
   "source": [
    "prepared_sentences = prepare_sentence_DF(all_sentences, 'laptop', 'desktop')\n",
    "\n",
    "classification_results = classify_sentences(prepared_sentences, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: inflect in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (5.5.2)\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install inflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_sentences = prepare_sentence_DF(all_sentences, 'laptop', 'desktop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prepared_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 425(/429) words with glove vectors\n",
      "Vocab size : 425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebook/cam/src/Backend/cam_pretrained/infersent/models.py:197: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  sentences = np.array(sentences)[idx_sort]\n",
      "/notebook/cam/src/Backend/cam_pretrained/infersent/models.py:209: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  sentences[stidx:stidx + bsize]), volatile=True)\n"
     ]
    }
   ],
   "source": [
    "prepared_sentences = prepare_sentence_DF(all_sentences, 'laptop', 'desktop')\n",
    "classification_results = classify_sentences(prepared_sentences, 'infersent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, elem in enumerate(all_sentences[:5]):\n",
    "    print (objects[0])\n",
    "    print (ind, elem, classification_results.iloc[ind])\n",
    "    print (\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install inltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BETTER', 'NONE', 'WORSE'], dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import joblib\n",
    "\n",
    "sys.modules['sklearn.externals.joblib'] = joblib\n",
    "sys.path.append(\"/notebook/cam/src/Backend/cam_pretrained/infersent\")\n",
    "\n",
    "\n",
    "def load_model1(model='data/model.pkl', glove_path='data/glove.840B.300d.txt',\n",
    "               infersent_path='data/infersent.allnli.pickle'):\n",
    "    \"\"\"\n",
    "    :param model:  path to the model which should be loaded\n",
    "    :param glove_path:  path to the glove embeddings\n",
    "    :param infersent_path: path to the saved infersent model\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    model = joblib.load(model)\n",
    "    if glove_path and infersent_path:\n",
    "        model.named_steps['infersentfeature'].glove_path = glove_path\n",
    "        model.named_steps['infersentfeature'].infersent_path = infersent_path\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.21.3'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "sys.modules['sklearn.externals.joblib'] = joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "#sys.modules['sklearn.externals.joblib'] = joblib\n",
    "sys.path.append(\"/notebook/cam/src/Backend/cam_pretrained/infersent\")\n",
    "\n",
    "\n",
    "def load_model(model='/notebook/cam/src/Backend/data/bow_model.pkl'):\n",
    "    \"\"\"\n",
    "    :param model:  path to the model which should be loaded\n",
    "    :param glove_path:  path to the glove embeddings\n",
    "    :param infersent_path: path to the saved infersent model\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    model = joblib.load(model)\n",
    "    if glove_path and infersent_path:\n",
    "        model.named_steps['infersentfeature'].glove_path = glove_path\n",
    "        model.named_steps['infersentfeature'].infersent_path = infersent_path\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path='/notebook/cam/src/Backend/data/glove.840B.300d.txt'\n",
    "infersent_path='/notebook/cam/src/Backend/data//infersent.allnli.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import joblib\n",
    "sys.path.append(\"/notebook/cam/src/Backend/cam_pretrained/infersent\")\n",
    "\n",
    "\n",
    "\n",
    "#model = joblib.load(\"/notebook/cam/src/Backend/data/infersent_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.named_steps['infersentfeature'].glove_path = glove_path\n",
    "model.named_steps['infersentfeature'].infersent_path = infersent_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cam_pretrained.infersent.infersent_feature.InfersentFeature at 0x7f4987fcdd90>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_steps['infersentfeature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(self._parameters.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_proba(prepared_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(glove_path, encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        word, vec = line.split(' ', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/notebook/cam/src/Backend/data/glove.840B.300d.txt',)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/notebook/Touche22/test/fune_tune_colbert.txt') as file:\n",
    "    lines = file.readlines()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'NEUTRAL', 'Q0', 'clueweb12-0207wb-45-15666___12', '1', '1.0', '\"Colbert', 'fine-tune\"']\n",
      "['1', 'SECOND', 'Q0', 'clueweb12-0207wb-45-15666___4', '2', '0.5', '\"Colbert', 'fine-tune\"']\n",
      "['1', 'NEUTRAL', 'Q0', 'clueweb12-0001wb-72-30848___1', '3', '0.3333333333333333', '\"Colbert', 'fine-tune\"']\n"
     ]
    }
   ],
   "source": [
    "for line in lines[:3]:\n",
    "    print (line.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('run.txt', 'w') as fp:\n",
    "    for line in lines:\n",
    "        fp.write(line)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp.write('\\n'.join('%s %s %s %s %s %s' % x for x in lines))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
