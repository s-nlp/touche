{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "868655\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('touche-task2-passages-version-002.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "    \n",
    "collection_list = {}\n",
    "maps = {}\n",
    "\n",
    "print (len(json_list))\n",
    "for ind, json_str in enumerate(json_list):\n",
    "    result = json.loads(json_str)\n",
    "    collection_list.update({result['id']: result['contents']})\n",
    "    maps.update({ind: result['id']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/notebook/Touche22/test/id_doc_map22.pickle', 'rb') as handle:\n",
    "    mapping_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '12162', '1']\n",
      "['0', '9524', '2']\n",
      "['0', '9163', '3']\n",
      "['0', '12417', '4']\n",
      "['0', '12254', '5']\n",
      "['0', '11878', '6']\n",
      "['0', '11485', '7']\n",
      "['0', '10904', '8']\n",
      "['0', '12667', '9']\n",
      "['0', '8706', '10']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "tsv_file = open(\"/notebook/Touche22/test/ranking_test_trained_by_me.tsv\")\n",
    "read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "\n",
    "common_list = []\n",
    "i = 0\n",
    "for row in read_tsv:\n",
    "    if (i < 10):\n",
    "        print(row)\n",
    "        i = i +1\n",
    "    doq_n = str(int(row[0]))\n",
    "    pass_idx = mapping_dict[int(row[1])]\n",
    "    rank = row[2]\n",
    "    \n",
    "    res_str = doq_n + ' Q0 ' + str(pass_idx) + \" \" + str(rank) + \" \" + str(1./int(rank))+ \" colbert\"\n",
    "    \n",
    "    common_list.append(res_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/notebook/Touche22/test/titles.pickle', 'rb') as handle:\n",
    "    titles = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Which is better, a laptop or a desktop?',\n",
       " 'Which is better, Canon or Nikon?',\n",
       " 'What are the advantages and disadvantages of PHP over Python and vice versa?',\n",
       " 'Why is Linux better than Windows?',\n",
       " 'Train or plane? Which is the better choice?',\n",
       " 'Should one prefer Chinese medicine or Western medicine?',\n",
       " 'Do you prefer cats or dogs, and why?',\n",
       " 'What is the better way to grill outdoors: gas or charcoal?',\n",
       " 'Which is better, MAC or PC?',\n",
       " 'Which is better, Pepsi or Coke?',\n",
       " 'What is better, Google search or Yahoo search?',\n",
       " 'Which browser is better, Internet Explorer or Firefox?',\n",
       " 'Which is a better vehicle: BMW or Audi?',\n",
       " 'Which one is better, an electric stove or a gas stove?',\n",
       " 'What planes are best, Boeing or Airbus?',\n",
       " 'Should I buy an Xbox or a PlayStation?',\n",
       " 'What is better: ASP or PHP?',\n",
       " 'What is better for the environment, a real or a fake Christmas tree?',\n",
       " 'What IDE is better for Java: NetBeans or Eclipse?',\n",
       " 'Is OpenGL better than Direct3D in terms of portability to different platforms?',\n",
       " 'Which four wheel truck is better: Ford or Toyota?',\n",
       " 'Should I prefer a Leica camera over Nikon for portrait photographs?',\n",
       " 'Is pasta healthier than pizza?',\n",
       " 'What is better at reducing fever in children, Ibuprofen or Aspirin?',\n",
       " 'Should I buy steel or ceramic knives?',\n",
       " 'Is morning or afternoon sun the best for fruit trees?',\n",
       " 'What is better for back pain, chiropractic therapy or physical therapy?',\n",
       " 'Is Kenya or Tanzania better for a safari?',\n",
       " 'Which is better, Family Guy or The Simpsons?',\n",
       " 'Which is more difficult, skiing or snowboarding?',\n",
       " 'Why is basketball better than football?',\n",
       " 'Who is stronger, Hulk or Superman?',\n",
       " 'Plastic pots or ceramic pots, which is better in terms of plant health?',\n",
       " 'Should I take the IELTS or the TOEFL?',\n",
       " 'Are online courses better than physical classrooms?',\n",
       " 'Who was a better boxer, Muhammad Ali or Joe Frazier?',\n",
       " \"Which technology performs better: Apple's or Google's?\",\n",
       " 'Who is better at learning a foreign language, kids or adults?',\n",
       " 'Which city is better, London or Paris?',\n",
       " 'Are artificial sweeteners better than white sugar?',\n",
       " 'Is it healthier to bake than to fry food?',\n",
       " 'Which algorithm is better, quicksort or merge sort?',\n",
       " 'What is better, cow milk or goat milk?',\n",
       " 'I am planning to buy sneakers: Which are better, Adidas or Nike?',\n",
       " 'Should I major in philosophy or psychology?',\n",
       " 'When are random forest classifiers better than decision trees?',\n",
       " 'What are the pros and cons of wood vs. stone mulch?',\n",
       " 'Is rain water better than tap water for plants?',\n",
       " 'Which is more environmentally friendly, a hybrid or a diesel?',\n",
       " 'Should I learn Python or R for data analysis?']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_common_list(common_list, numb):\n",
    "    ind_set = set()\n",
    "    for elem in common_list[:numb]:\n",
    "        elem = elem.split()\n",
    "        ind = int(elem[0])\n",
    "        #pass_idx = doc_ind2pass[elem[2]]\n",
    "        if ind not in ind_set:\n",
    "            print (titles[ind])\n",
    "            ind_set.add(ind)\n",
    "            print (\"\\n\")\n",
    "            try:\n",
    "                print (collection_list[elem[2]])\n",
    "            except:\n",
    "                print (\"bls\")\n",
    "            print (\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which is better, a laptop or a desktop?\n",
      "\n",
      "\n",
      "laptop A laptop is any computer designed to do pretty much anything a desktop system can do but run for a short time (usually two to five hours) on batteries. They are designed to be carried around but are not particularly convenient to carry around. They are significantly more expensive than desktop systems and have far worse battery life thanPDAs. Calling a system a laptop implies nothing about its platform. By far the fastest laptops are thePowerPC basedMacintoshes. memory Computer memory is used to temporarily store data. In reality, computer memory is only capable of remembering sequences of zeros and ones, but by utilizing thebinary number system it is possible to produce arbitrary rational numbers and through cleverformatting all manner of representations of pictures, sounds, and animations. The most common types of memory areRAM, ROM, and flash. MHz & megahertz One megahertz is equivalent to 1000 kilohertz, or 1,000,000 hertz.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_common_list(common_list, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '54353', '1']\n",
      "['0', '54345', '2']\n",
      "['0', '7883', '3']\n",
      "['0', '9524', '4']\n",
      "['0', '12171', '5']\n",
      "['0', '8329', '6']\n",
      "['0', '7890', '7']\n",
      "['0', '9691', '8']\n",
      "['0', '12162', '9']\n",
      "['0', '12121', '10']\n"
     ]
    }
   ],
   "source": [
    "tsv_file = open(\"/notebook/Touche22/test/ranking_7.tsv\")\n",
    "read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "\n",
    "common_list = []\n",
    "i = 0\n",
    "for row in read_tsv:\n",
    "    if (i < 10):\n",
    "        print(row)\n",
    "        i = i +1\n",
    "    doq_n = str(int(row[0]))\n",
    "    pass_idx = mapping_dict[int(row[1])]\n",
    "    rank = row[2]\n",
    "    \n",
    "    res_str = doq_n + ' Q0 ' + str(pass_idx) + \" \" + str(rank) + \" \" + str(1./int(rank))+ \" colbert\"\n",
    "    \n",
    "    common_list.append(res_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print_common_list(common_list, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('objects.pickle', 'rb') as handle:\n",
    "    objects = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/notebook/cam/src/Backend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = []\n",
    "for elem in common_list[:50]:\n",
    "    elem = elem.split()\n",
    "    ind = int(elem[0])\n",
    "    #pass_idx = doc_ind2pass[elem[2]]\n",
    "    \n",
    "    all_sentences.append(collection_list[elem[2]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['laptop, desktop', 'Canon, Nikon']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from ml_approach.classify import (classify_sentences, evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_approach.sentence_preparation_ML import prepare_sentence_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/bow_model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-92280be4b67a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprepared_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_sentence_DF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'laptop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'desktop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclassification_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepared_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/notebook/cam/src/Backend/ml_approach/classify.py\u001b[0m in \u001b[0;36mclassify_sentences\u001b[0;34m(sentences, model)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         model = load_model('data/bow_model.pkl',\n\u001b[0;32m---> 17\u001b[0;31m                            glove_path=None, infersent_path=None)\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebook/cam/src/Backend/cam_pretrained/model_util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(model, glove_path, infersent_path)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \"\"\"\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mglove_path\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minfersent_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'infersentfeature'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglove_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglove_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_read_fileobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/bow_model.pkl'"
     ]
    }
   ],
   "source": [
    "prepared_sentences = prepare_sentence_DF(all_sentences, 'laptop', 'desktop')\n",
    "\n",
    "classification_results = classify_sentences(prepared_sentences, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: inflect in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (5.5.2)\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install inflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_sentences = prepare_sentence_DF(all_sentences, 'laptop', 'desktop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prepared_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 425(/429) words with glove vectors\n",
      "Vocab size : 425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebook/cam/src/Backend/cam_pretrained/infersent/models.py:197: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  sentences = np.array(sentences)[idx_sort]\n",
      "/notebook/cam/src/Backend/cam_pretrained/infersent/models.py:209: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  sentences[stidx:stidx + bsize]), volatile=True)\n"
     ]
    }
   ],
   "source": [
    "classification_results = classify_sentences(prepared_sentences, 'infersent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BETTER</th>\n",
       "      <th>NONE</th>\n",
       "      <th>WORSE</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.116762</td>\n",
       "      <td>0.735651</td>\n",
       "      <td>0.147587</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.999534</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001990</td>\n",
       "      <td>0.997840</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001807</td>\n",
       "      <td>0.997611</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     BETTER      NONE     WORSE   max\n",
       "0  0.116762  0.735651  0.147587  NONE\n",
       "1  0.000448  0.999534  0.000018  NONE\n",
       "2  0.001990  0.997840  0.000170  NONE\n",
       "3  0.001807  0.997611  0.000582  NONE"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_results[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laptop, desktop\n",
      "0 laptop A laptop is any computer designed to do pretty much anything a desktop system can do but run for a short time (usually two to five hours) on batteries. They are designed to be carried around but are not particularly convenient to carry around. They are significantly more expensive than desktop systems and have far worse battery life thanPDAs. Calling a system a laptop implies nothing about its platform. By far the fastest laptops are thePowerPC basedMacintoshes. memory Computer memory is used to temporarily store data. In reality, computer memory is only capable of remembering sequences of zeros and ones, but by utilizing thebinary number system it is possible to produce arbitrary rational numbers and through cleverformatting all manner of representations of pictures, sounds, and animations. The most common types of memory areRAM, ROM, and flash. MHz & megahertz One megahertz is equivalent to 1000 kilohertz, or 1,000,000 hertz. BETTER    0.116762\n",
      "NONE      0.735651\n",
      "WORSE     0.147587\n",
      "max           NONE\n",
      "Name: 0, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "laptop, desktop\n",
      "1 Text typed into the computer will usually appear at the cursor. database A database is a collection of data, typically organized to make common retrievals easy and efficient. Some common database programs include Oracle, Sybase,Postgres, Informix, Filemaker, Adabas, etc. desktop A desktop system is a computer designed to sit in one position on a desk somewhere and not move around. Most general purpose computers are desktop systems. Calling a system a desktop implies nothing about its platform. The fastest desktop system at any given time is typically either anAlpha or PowerPC based system, but theSPARC and PA-RISC based systems are also often in the running. Industrial strength desktops are typically calledworkstations. directory Also called \"folder\", a directory is a collection of files typically created for organizational purposes. Note that a directory is itself a file, so a directory can generally contain other directories. BETTER    0.000447816\n",
      "NONE         0.999534\n",
      "WORSE     1.81292e-05\n",
      "max              NONE\n",
      "Name: 1, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "laptop, desktop\n",
      "2 Laptop - Wikipedia, the free encyclopedia Laptop From Wikipedia, the free encyclopedia Jump to: navigation, search A modern laptop computer A laptop is a personal computer for mobile use.[1] A laptop integrates most of thetypical components of a desktop computer, including a display, a keyboard, a pointing device (a touchpad, also known as a trackpad or pointing stick) and speakers into a single unit. A laptop is powered by mains electricity via an AC adapter, and can be used away from an outlet using a rechargeable battery. Portable computers, originally monochrome CRT-based and developed into the modern laptops, were originally considered to be a small niche market, mostly for specialized field applications such as the military, accountants and sales representatives. As portable computers became smaller, lighter, cheaper, more powerful and as screens became larger and of better quality, laptops became very widely used for all sorts of purposes. BETTER     0.00199036\n",
      "NONE          0.99784\n",
      "WORSE     0.000169745\n",
      "max              NONE\n",
      "Name: 2, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "laptop, desktop\n",
      "3 reprinted with permission from HP In the not-so-distant past, the choice between a desktop and a laptop computer was simple: do you want portability, or not? There were a few other clear-cut differences, too. Desktop models offered more power and features and were less expensive, while laptops were portable, but also more costly, and less ergonomic. While some of these differences remain, advances in technology make many of them insignificant. Laptop prices have fallen, and the machines now offer even more power and features. Desktop models are less bulky than they used to be, and with the proliferation of devices like USBs, portability of data is not such a big issue. So how do you choose? Here are a few points to consider. What's your workspace like? Space is a big factor to consider. BETTER    0.00180694\n",
      "NONE        0.997611\n",
      "WORSE     0.00058249\n",
      "max             NONE\n",
      "Name: 3, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "laptop, desktop\n",
      "4 Setting up a Notebook versus a Desktop Setting up a Notebook versus a Desktop Introduction This document is targeted at all recipients of Client Managed PCs here at the University of Waterloo. Since most of these are notebooks in Academic Support, the additional focus is specifically at portables however, many of the concerns covered are those of desktop PC owners that manage their own PCs. Desktop PCs in Academic Support are used differently than notebooks and because they rarely leave the users office they are almost all imaged and managed by IST. Definition of Terms The term “notebook” is used throughout this document to mean a combination of all laptops and tablets. A laptop is a portable PC. A tablet is a portable PC with a touch-sensitive screen. This screen allows for the use of a special pen, to act as a mouse or enter text or objects, as you might on a pad of paper. BETTER     0.0640949\n",
      "NONE        0.935722\n",
      "WORSE     0.00018345\n",
      "max             NONE\n",
      "Name: 4, dtype: object\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, row in classification_results.iterrows():\n",
    "    print(row['max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install inltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BETTER', 'NONE', 'WORSE'], dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import joblib\n",
    "\n",
    "sys.modules['sklearn.externals.joblib'] = joblib\n",
    "sys.path.append(\"/notebook/cam/src/Backend/cam_pretrained/infersent\")\n",
    "\n",
    "\n",
    "def load_model1(model='data/model.pkl', glove_path='data/glove.840B.300d.txt',\n",
    "               infersent_path='data/infersent.allnli.pickle'):\n",
    "    \"\"\"\n",
    "    :param model:  path to the model which should be loaded\n",
    "    :param glove_path:  path to the glove embeddings\n",
    "    :param infersent_path: path to the saved infersent model\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    model = joblib.load(model)\n",
    "    if glove_path and infersent_path:\n",
    "        model.named_steps['infersentfeature'].glove_path = glove_path\n",
    "        model.named_steps['infersentfeature'].infersent_path = infersent_path\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.21.3'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "sys.modules['sklearn.externals.joblib'] = joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "#sys.modules['sklearn.externals.joblib'] = joblib\n",
    "sys.path.append(\"/notebook/cam/src/Backend/cam_pretrained/infersent\")\n",
    "\n",
    "\n",
    "def load_model(model='/notebook/cam/src/Backend/data/bow_model.pkl'):\n",
    "    \"\"\"\n",
    "    :param model:  path to the model which should be loaded\n",
    "    :param glove_path:  path to the glove embeddings\n",
    "    :param infersent_path: path to the saved infersent model\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    model = joblib.load(model)\n",
    "    if glove_path and infersent_path:\n",
    "        model.named_steps['infersentfeature'].glove_path = glove_path\n",
    "        model.named_steps['infersentfeature'].infersent_path = infersent_path\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path='/notebook/cam/src/Backend/data/glove.840B.300d.txt'\n",
    "infersent_path='/notebook/cam/src/Backend/data//infersent.allnli.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import joblib\n",
    "sys.path.append(\"/notebook/cam/src/Backend/cam_pretrained/infersent\")\n",
    "\n",
    "\n",
    "\n",
    "model = joblib.load(\"/notebook/cam/src/Backend/data/infersent_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.named_steps['infersentfeature'].glove_path = glove_path\n",
    "model.named_steps['infersentfeature'].infersent_path = infersent_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cam_pretrained.infersent.infersent_feature.InfersentFeature at 0x7f4987fcdd90>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_steps['infersentfeature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(self._parameters.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 425(/429) words with glove vectors\n",
      "Vocab size : 425\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LSTM' object has no attribute 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-d2b8c5680d87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepared_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebook/cam/src/Backend/cam_pretrained/infersent/infersent_feature.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, sentences)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0minfersent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_glove_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglove_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0minfersent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0minfersent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfersent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mencode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfersent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1187\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LSTM' object has no attribute 'list'"
     ]
    }
   ],
   "source": [
    "model.predict_proba(prepared_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-bea0f1f0a88c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not tuple"
     ]
    }
   ],
   "source": [
    "with open(glove_path, encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        word, vec = line.split(' ', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/notebook/cam/src/Backend/data/glove.840B.300d.txt',)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
